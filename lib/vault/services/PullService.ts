"use client";

import { db } from '@/lib/offlineDB';
import { identityManager } from '../core/IdentityManager';
import { normalizeRecord, validateCompleteness } from '../core/VaultUtils';
import { getTimestamp } from '@/lib/shared/utils';
import { validateBook, validateEntry } from '../core/schemas';
import { getVaultStore } from '../store/storeHelper';
import { LicenseVault, RiskManager } from '../security';
import { generateVaultSignature, prepareSignedHeaders, preparePayload } from '../utils/security';

/**
 * üöÄ SMART BATCH PROCESSOR - Intelligent batching with payload size detection
 * Reused from PushService for consistency
 */
class SmartBatchProcessor<T> {
  private readonly DEFAULT_BATCH_SIZE = 20; // Pull batches of 20 items
  private readonly LARGE_PAYLOAD_THRESHOLD = 10240; // 10KB in bytes

  /**
   * üìä Create intelligent batches based on JSON payload size
   */
  createSmartBatches(items: T[]): T[][] {
    const batches: T[][] = [];
    
    for (let i = 0; i < items.length; i++) {
      const item = items[i];
      
      // üéØ SIZE CHECK: Calculate JSON string size
      const jsonSize = JSON.stringify(item).length;
      
      if (jsonSize > this.LARGE_PAYLOAD_THRESHOLD) {
        // üì¶ SINGLE-ITEM BATCH: Large payload (likely image)
        console.log(`üì¶ [SMART BATCH] Large payload detected (${jsonSize} bytes), creating single-item batch`);
        batches.push([item]);
      } else {
        // üì¶ NORMAL BATCHING: Group small items together
        let currentBatch = batches[batches.length - 1];
        if (!currentBatch || currentBatch.length >= this.DEFAULT_BATCH_SIZE) {
          currentBatch = [];
          batches.push(currentBatch);
        }
        currentBatch.push(item);
      }
    }
    
    return batches;
  }

  /**
   * üìè Calculate optimal delay based on server response time
   */
  calculateOptimalDelay(previousResponseTime: number, previousFailed: boolean): number {
    const BASE_DELAY = 1000; // 1 second for pull (faster than push)
    const SLOW_RESPONSE_THRESHOLD = 3000; // 3 seconds
    const SLOW_RESPONSE_DELAY = 2000; // 2 seconds
    
    if (previousFailed) {
      // üîÑ EXPONENTIAL BACKOFF: Double delay on failure
      return BASE_DELAY * 2;
    }
    
    if (previousResponseTime > SLOW_RESPONSE_THRESHOLD) {
      // ‚è∞ ADAPTIVE THROTTLING: Increase delay for slow responses
      return SLOW_RESPONSE_DELAY;
    }
    
    return BASE_DELAY;
  }
}

/**
 * üìä SYNC PROGRESS TRACKER - State management integration
 * Reused from PushService for consistency
 */
class SyncProgressTracker {
  private currentBatch = 0;
  private totalBatches = 0;
  private totalItems = 0;
  private processedItems = 0;
  private startTime = Date.now();
  private lastProgressUpdate = 0;
  private readonly PROGRESS_THROTTLE_MS = 1000; // Throttle updates to once per second
  private readonly BATCH_UPDATE_INTERVAL = 5; // Update after every 5 batches

  start(totalItems: number): void {
    this.totalItems = totalItems;
    this.processedItems = 0;
    this.currentBatch = 0;
    this.startTime = Date.now();
    this.lastProgressUpdate = 0;
    
    // üìä UPDATE ZUSTAND STATE
    const store = getVaultStore();
    store.updateSyncStats({
      totalSynced: 0,
      totalFailed: 0,
      lastSyncDuration: null
    });
    store.setSyncStatus('syncing');
    
    console.log(`üìä [PULL PROGRESS] Starting pull: ${totalItems} items`);
  }

  updateBatch(batchNumber: number, batchSize: number): void {
    this.currentBatch = batchNumber;
    this.processedItems += batchSize;
    
    const progress = (this.processedItems / this.totalItems) * 100;
    const elapsed = Date.now() - this.startTime;
    const estimatedRemaining = this.processedItems > 0 
      ? (elapsed / this.processedItems) * (this.totalItems - this.processedItems)
      : 0;
    
    // üöÄ PROGRESS THROTTLING: Update UI only once per second OR every 5 batches
    const now = Date.now();
    const shouldUpdateByTime = now - this.lastProgressUpdate >= this.PROGRESS_THROTTLE_MS;
    const shouldUpdateByBatches = batchNumber % this.BATCH_UPDATE_INTERVAL === 0;
    
    if (shouldUpdateByTime || shouldUpdateByBatches) {
      this.lastProgressUpdate = now;
      
      // üìä UPDATE ZUSTAND STATE (THROTTLED)
      const store = getVaultStore();
      store.updateSyncStats({
        totalSynced: this.processedItems,
        totalFailed: store.syncStats.totalFailed,
        lastSyncDuration: elapsed
      });
      store.setSyncProgress({
        total: this.totalItems,
        processed: this.processedItems,
        percentage: progress,
        eta: estimatedRemaining / 1000
      });
      
      console.log(`üìä [PULL PROGRESS] Batch ${batchNumber} - ${this.processedItems}/${this.totalItems} (${progress.toFixed(1)}%) - Est. remaining: ${(estimatedRemaining/1000).toFixed(1)}s`);
    }
  }

  recordFailure(): void {
    const store = getVaultStore();
    store.updateSyncStats({
      totalSynced: this.processedItems,
      totalFailed: store.syncStats.totalFailed + 1,
      lastSyncDuration: store.syncStats.lastSyncDuration
    });
  }

  complete(): void {
    const totalTime = Date.now() - this.startTime;
    
    // üìä UPDATE ZUSTAND STATE
    const store = getVaultStore();
    store.updateSyncStats({
      totalSynced: this.processedItems,
      totalFailed: store.syncStats.totalFailed,
      lastSyncDuration: totalTime
    });
    store.setSyncStatus('success');
    store.updateLastSyncedAt();
    
    console.log(`üìä [PULL PROGRESS] Pull completed in ${totalTime}ms`);
  }

  error(): void {
    const store = getVaultStore();
    store.setSyncStatus('error');
  }
}

/**
 * üöÄ PULL SERVICE - Industrial-grade batched data synchronization from server
 * Symmetric to PushService with fault-tolerant architecture
 */
export class PullService {
  private userId: string = '';
  private isPulling = false;
  private batchProcessor = new SmartBatchProcessor<any>();
  private _progressTracker = new SyncProgressTracker();

  constructor() {
    if (process.env.NODE_ENV === 'development') {
      console.log('üöÄ [PULL SERVICE] Initialized with fault-tolerant architecture');
    }
  }

  /**
   * üîç SECURITY CHECKS
   */
  private async performSecurityChecks(user: any): Promise<{ valid: boolean; error?: string }> {
    try {
      const licenseAccess = LicenseVault.validateAccess(user);
      if (!licenseAccess.access) {
        return { valid: false, error: 'License access denied' };
      }

      const lockdownStatus = RiskManager.isLockdown(user);
      if (lockdownStatus) {
        return { valid: false, error: 'User in lockdown' };
      }

      const signatureValid = await LicenseVault.verifySignature(user);
      if (!signatureValid) {
        return { valid: false, error: 'License signature invalid' };
      }

      return { valid: true };
    } catch (error) {
      return { valid: false, error: String(error) };
    }
  }

  /**
   * üîç TELEMETRY INTEGRITY VERIFICATION
   */
  private async verifyTelemetryIntegrity(maxRetries: number = 3): Promise<{ valid: boolean; error?: string }> {
    for (let attempt = 1; attempt <= maxRetries; attempt++) {
      try {
        const user = await db.users.where('userId').equals(this.userId).first();
        if (user) {
          // Success - user found, proceed with security checks
          return await this.performSecurityChecks(user);
        }
        
        if (attempt === maxRetries) {
          return { valid: false, error: 'User profile not found after retries' };
        }
        
        // ‚è±Ô∏è EXPONENTIAL BACKOFF: Non-blocking wait
        const delay = Math.min(Math.pow(2, attempt) * 100, 1000); // Cap at 1s
        console.log(`‚è≥ [PULL SECURITY] Retry ${attempt}/${maxRetries} in ${delay}ms...`);
        await new Promise(resolve => setTimeout(resolve, delay));
      } catch (error) {
        if (attempt === maxRetries) {
          return { valid: false, error: String(error) };
        }
        // Continue retry on error
      }
    }
    return { valid: false, error: 'User profile not found after maximum retries' };
  }

  /**
   * üöÄ BATCHED PULL PENDING DATA FROM SERVER
   */
  async pullPendingData(): Promise<{ success: boolean; itemsProcessed: number; errors: string[] }> {
    // üõ°Ô∏è SECURITY INTERLOCK: Verify telemetry first
    const telemetryResult = await this.verifyTelemetryIntegrity();
    if (!telemetryResult.valid) {
      console.error('üîí [PULL SERVICE] Security verification failed - blocking data pull');
      return { success: false, itemsProcessed: 0, errors: [telemetryResult.error || 'Security verification failed'] };
    }
    
    // LOCKDOWN GUARD: Check security state
    const { networkMode, isSecurityLockdown } = getVaultStore();
    if (networkMode === 'RESTRICTED' || isSecurityLockdown) {
      console.log('üîí [PULL SERVICE] Business data pull blocked - RESTRICTED mode');
      return { success: false, itemsProcessed: 0, errors: ['App in restricted mode'] };
    }
    
    // TRAFFIC POLICE: Check network state before proceeding
    if (networkMode === 'OFFLINE' || networkMode === 'DEGRADED') {
      console.warn('üõë [PULL SERVICE] Pull blocked. Network is:', networkMode);
      return { success: false, itemsProcessed: 0, errors: [] };
    }
    
    // FINAL SECURITY GUARD: Last line of defense
    const user = await db.users.where('userId').equals(this.userId).first();
    if (!user) {
      console.error('üîí [PULL SERVICE] User profile missing - Pull blocked');
      return { success: false, itemsProcessed: 0, errors: ['User profile missing'] };
    }

    const licenseAccess = LicenseVault.validateAccess(user);
    if (!licenseAccess.access) {
      console.error('üîí [PULL SERVICE] License invalid - Pull blocked');
      return { success: false, itemsProcessed: 0, errors: ['License access denied'] };
    }

    const lockdownStatus = RiskManager.isLockdown(user);
    if (lockdownStatus) {
      console.error('üîí [PULL SERVICE] User in lockdown - Pull blocked');
      return { success: false, itemsProcessed: 0, errors: ['User in lockdown'] };
    }

    const signatureValid = await LicenseVault.verifySignature(user);
    if (!signatureValid) {
      console.error('üîí [PULL SERVICE] License signature invalid - Pull blocked');
      return { success: false, itemsProcessed: 0, errors: ['License signature invalid'] };
    }

    if (this.isPulling) {
      console.log('üöÄ [BATCH PULL SERVICE] Already pulling, skipping...');
      return { success: false, itemsProcessed: 0, errors: ['Already pulling'] };
    }

    this.isPulling = true;
    const errors: string[] = [];
    let itemsProcessed = 0;

    try {
      if (process.env.NODE_ENV === 'development') {
        console.log('üöÄ [BATCH PULL SERVICE] Starting industrial-grade batched pull sync...');
      }
      
      // üéØ PRIORITY 0: USER SETTINGS FIRST (MUST COMPLETE BEFORE DATA)
      const userSettingsResult = await this.pullUserSettings();
      if (!userSettingsResult.success) {
        errors.push(userSettingsResult.error || 'Failed to pull user settings');
      }
      
      // üéØ PRIORITY 1: BOOKS FIRST (MUST COMPLETE BEFORE ENTRIES)
      const booksResult = await this.pullBatchedBooks();
      itemsProcessed += booksResult.processed;
      errors.push(...booksResult.errors);
      
      // üéØ PRIORITY 2: ENTRIES (ONLY AFTER ALL BOOKS SUCCESS)
      if (booksResult.success) {
        const entriesResult = await this.pullBatchedEntries();
        itemsProcessed += entriesResult.processed;
        errors.push(...entriesResult.errors);
      } else {
        errors.push('Skipping entries due to book pull failures');
      }
      
      if (errors.length === 0) {
        this._progressTracker.complete();
      } else {
        this._progressTracker.error();
      }
      
      if (process.env.NODE_ENV === 'development') {
        console.log('‚úÖ [BATCH PULL SERVICE] Industrial-grade batched pull complete:', { itemsProcessed, errors });
      }
      return { success: errors.length === 0, itemsProcessed, errors };
      
    } catch (error) {
      console.error('‚ùå [BATCH PULL SERVICE] Pull sync failed:', error);
      errors.push(`Pull sync failed: ${error}`);
      this._progressTracker.error();
      return { success: false, itemsProcessed, errors };
    } finally {
      this.isPulling = false;
    }
  }

  /**
   * üßë PULL USER SETTINGS - Fetch user profile and update local state
   */
  private async pullUserSettings(): Promise<{ success: boolean; error?: string }> {
    try {
      console.log('üßë [PULL SERVICE] Fetching user settings from server...');
      
      const response = await fetch(`/api/user/profile?userId=${encodeURIComponent(this.userId)}`);
      
      if (!response.ok) {
        if (response.status === 404) {
          console.warn('‚ö†Ô∏è [PULL SERVICE] User profile not found on server, using local defaults');
          return { success: true }; // Not an error, just use local defaults
        }
        throw new Error(`Failed to fetch user profile: ${response.statusText}`);
      }
      
      const result = await response.json();
      const user = result.user;
      
      if (!user) {
        console.warn('‚ö†Ô∏è [PULL SERVICE] No user data in response');
        return { success: true }; // Use local defaults
      }
      
      // üéØ UPDATE LOCAL ZUSTAND STATE
      const store = getVaultStore();
      
      // Extract user settings
      const { categories, currency, preferences } = user;
      
      // Update store if values are present
      if (categories && Array.isArray(categories)) {
        // Note: You may need to add setCategories to the store if it doesn't exist
        console.log('üìù [PULL SERVICE] Updating categories:', categories);
        if (store.setCategories) {
          store.setCategories(categories);
        }
      }
      
      if (currency && typeof currency === 'string') {
        console.log('üí∞ [PULL SERVICE] Updating currency:', currency);
        if (store.setCurrency) {
          store.setCurrency(currency);
        }
      }
      
      if (preferences && typeof preferences === 'object') {
        console.log('‚öôÔ∏è [PULL SERVICE] Updating preferences:', preferences);
        if (store.setPreferences) {
          store.setPreferences(preferences);
        }
      }
      
      console.log('‚úÖ [PULL SERVICE] User settings pulled successfully');
      return { success: true };
      
    } catch (error) {
      console.error('‚ùå [PULL SERVICE] Failed to pull user settings:', error);
      return { success: false, error: String(error) };
    }
  }

  /**
   * üìö PULL BATCHED BOOKS with checkpoint resume capability
   */
  private async pullBatchedBooks(): Promise<{ success: boolean; processed: number; errors: string[] }> {
    const errors: string[] = [];
    let processed = 0;
    let previousResponseTime = 0;
    let previousFailed = false;

    try {
      // üîÑ START FROM BEGINNING: Simplified pull without checkpoints
      let offset = 0;
      let lastSequence = 0;
      
      console.log('üöÄ [BATCH PULL SERVICE] Starting books pull from offset:', offset);
      
      let hasMore = true;
      const totalBatches = Math.ceil(5000 / 20); // Estimate total batches
      this._progressTracker.start(totalBatches * 20); // Estimate total items
      
      // üîÑ BATCH PROCESSING WITH ADAPTIVE THROTTLING
      let batchIndex = 0;
      let consecutiveEmptyBatches = 0;
      const maxLoopCount = 500;
      
      while (hasMore && batchIndex < maxLoopCount) {
        batchIndex++;
        console.log(`üöÄ [BATCH PULL SERVICE] Processing book batch ${batchIndex} from offset ${offset}`);
        
        const batchStartTime = Date.now();
        let batchSuccess = true;
        
        try {
          // üéØ BATCHED NETWORK REQUEST (not local batching)
          const response = await fetch(
            `/api/books?userId=${encodeURIComponent(this.userId)}&limit=20&offset=${offset}&sequenceAfter=${lastSequence}`
          );
          
          if (!response.ok) {
            throw new Error(`Server response: ${response.status}`);
          }
          
          const batch = await response.json();
          const books = batch.data || batch.books || [];
          
          if (books.length === 0) {
            consecutiveEmptyBatches++;
            console.warn(`‚ö†Ô∏è [PULL SERVICE] Empty batch ${batchIndex} - consecutive empties: ${consecutiveEmptyBatches}`);
            
            // üõ°Ô∏è MAX-TRY GUARD: Stop after 3 consecutive empty batches
            if (consecutiveEmptyBatches >= 3) {
              console.error('üö® [PULL SERVICE] Max consecutive empty batches reached, stopping pull to prevent infinite loop');
              // Log critical telemetry event
              await db.audits.add({
                userId: this.userId,
                type: 'SECURITY',
                event: 'INFINITE_LOOP_PREVENTED',
                details: `Stopped after ${batchIndex} batches with ${consecutiveEmptyBatches} consecutive empties`,
                timestamp: Date.now(),
                severity: 'CRITICAL'
              });
              hasMore = false;
              break;
            }
            
            // Continue to next batch
            offset += 20;
            continue;
          } else {
            consecutiveEmptyBatches = 0; // Reset counter on successful batch
          }
          
          // üõ°Ô∏è SEQUENCE NUMBER VERIFICATION
          const validBooks = books.filter((book: any) => 
            book.sequenceNumber > lastSequence
          );
          
          console.log(`üöÄ [BATCH PULL SERVICE] Retrieved ${books.length} books, ${validBooks.length} valid after sequence check`);
          
          // üîÑ COMMIT BATCH - ATOMIC TRANSACTION WITH QUOTA SAFETY
          try {
            await db.transaction('rw', db.books, db.syncPoints, async () => {
              for (const book of validBooks) {
                try {
                  // ÔøΩ [AUDIT] Log server payload to see what we're getting
                  console.log('üì° [PULL PAYLOAD]', { id: book._id, image: book.image, mediaCid: book.mediaCid, localId: book.localId });
                  
                  // ÔøΩüõ°Ô∏è SAFETY GUARD: Validate completeness before storing
                  const validation = validateCompleteness(book, 'book');
                  if (!validation.isValid) {
                    errors.push(`Book ${book.cid} validation failed: ${validation.missingFields.join(', ')}`);
                    batchSuccess = false;
                    continue;
                  }
                  
                  const result = await this.commitSingleBook(book);
                  if (result.success) {
                    processed++;
                    
                    // üåê BACKGROUND MEDIA DOWNLOAD: Use saved record with localId
                    const savedBook = await db.books.where('cid').equals(book.cid).first();
                    if (savedBook?.image && savedBook.image.startsWith('http') && savedBook.localId) {
                      this.hydrateMissingMedia(savedBook.image, savedBook.localId).catch(error => {
                        console.warn(`‚ö†Ô∏è [PULL SERVICE] Background media download failed for book ${savedBook.localId}:`, error);
                      });
                    } else {
                      console.warn('üö´ [PULL SERVICE] Media download blocked - missing data:', {
                        hasImage: !!savedBook?.image,
                        isHttp: savedBook?.image?.startsWith('http'),
                        hasLocalId: !!savedBook?.localId,
                        bookId: savedBook?.localId
                      });
                    }
                  } else {
                    errors.push(result.error || `Failed to commit book ${book.cid}`);
                    batchSuccess = false;
                  }
                } catch (error) {
                  errors.push(`Book ${book.cid} commit failed: ${error}`);
                  batchSuccess = false;
                }
              }
              
              // üéØ BATCH PROCESSING: Simplified without checkpoint saving
              if (validBooks.length > 0) {
                const maxSequence = Math.max(...validBooks.map((b: any) => b.sequenceNumber || 0));
                console.log(`‚úÖ [BATCH PULL SERVICE] Processed batch ${batchIndex} with ${validBooks.length} books, max sequence: ${maxSequence}`);
                lastSequence = maxSequence;
              }
            });
          } catch (error: any) {
            // üíæ STORAGE QUOTA SAFETY: Handle quota exceeded gracefully
            if (error.name === 'QuotaExceededError' || error.message?.includes('quota')) {
              console.error('üíæ [PULL SERVICE] Storage quota exceeded, pausing sync gracefully');
              errors.push('Storage quota exceeded - please free up space');
              hasMore = false;
              break;
            } else {
              throw error; // Re-throw non-quota errors
            }
          }
          
          // üìä RECORD RESPONSE TIME AND CALCULATE DELAY
          const responseTime = Date.now() - batchStartTime;
          previousResponseTime = responseTime;
          previousFailed = !batchSuccess;
          
          // ‚è∞ ADAPTIVE THROTTLING
          const delay = this.batchProcessor.calculateOptimalDelay(responseTime, !batchSuccess);
          if (hasMore) {
            console.log(`üöÄ [BATCH PULL SERVICE] Waiting ${delay}ms before next batch (response: ${responseTime}ms, success: ${batchSuccess})...`);
            await new Promise(resolve => setTimeout(resolve, delay));
          }
          
          // üîÑ UPDATE OFFSET
          offset += books.length;
          
          // üîç CHECK COMPLETION
          hasMore = books.length === 20 && !batch.isComplete;
          
          this._progressTracker.updateBatch(batchIndex, validBooks.length);
          
        } catch (error) {
          console.error(`‚ùå [BATCH PULL SERVICE] Book batch ${batchIndex} failed:`, error);
          errors.push(`Book batch ${batchIndex} failed: ${error}`);
          batchSuccess = false;
          previousFailed = true;
          
          // Continue to next batch on failure
          offset += 20;
          hasMore = true;
        }
      }

      return { success: errors.length === 0, processed, errors };
    } catch (error) {
      console.error('‚ùå [BATCH PULL SERVICE] Books pull failed:', error);
      errors.push(`Books pull failed: ${error}`);
      return { success: false, processed, errors };
    }
  }

  /**
   * üìù PULL BATCHED ENTRIES with checkpoint resume capability
   */
  private async pullBatchedEntries(): Promise<{ success: boolean; processed: number; errors: string[] }> {
    const errors: string[] = [];
    let processed = 0;
    let previousResponseTime = 0;
    let previousFailed = false;

    try {
      // üîÑ START FROM BEGINNING: Simplified pull without checkpoints
      let offset = 0;
      let lastSequence = 0;
      
      console.log('üöÄ [BATCH PULL SERVICE] Starting entries pull from offset:', offset);
      
      let hasMore = true;
      
      // üîÑ BATCH PROCESSING WITH ADAPTIVE THROTTLING
      let batchIndex = 0;
      let consecutiveEmptyBatches = 0;
      const maxLoopCount = 500;
      
      while (hasMore && batchIndex < maxLoopCount) {
        batchIndex++;
        console.log(`üöÄ [BATCH PULL SERVICE] Processing entry batch ${batchIndex} from offset ${offset}`);
        
        const batchStartTime = Date.now();
        let batchSuccess = true;
        
        try {
          // üéØ BATCHED NETWORK REQUEST (not local batching)
          const response = await fetch(
            `/api/entries?userId=${encodeURIComponent(this.userId)}&limit=20&offset=${offset}&sequenceAfter=${lastSequence}`
          );
          
          if (!response.ok) {
            throw new Error(`Server response: ${response.status}`);
          }
          
          const batch = await response.json();
          const entries = batch.data || batch.entries || [];
          
          if (entries.length === 0) {
            consecutiveEmptyBatches++;
            console.warn(`‚ö†Ô∏è [PULL SERVICE] Empty batch ${batchIndex} - consecutive empties: ${consecutiveEmptyBatches}`);
            
            // üõ°Ô∏è MAX-TRY GUARD: Stop after 3 consecutive empty batches
            if (consecutiveEmptyBatches >= 3) {
              console.error('üö® [PULL SERVICE] Max consecutive empty batches reached, stopping pull to prevent infinite loop');
              // Log critical telemetry event
              await db.audits.add({
                userId: this.userId,
                type: 'SECURITY',
                event: 'INFINITE_LOOP_PREVENTED',
                details: `Stopped after ${batchIndex} batches with ${consecutiveEmptyBatches} consecutive empties`,
                timestamp: Date.now(),
                severity: 'CRITICAL'
              });
              hasMore = false;
              break;
            }
            
            // Continue to next batch
            offset += 20;
            continue;
          } else {
            consecutiveEmptyBatches = 0; // Reset counter on successful batch
          }
          
          // üõ°Ô∏è SEQUENCE NUMBER VERIFICATION
          const validEntries = entries.filter((entry: any) => 
            entry.sequenceNumber > lastSequence
          );
          
          console.log(`üöÄ [BATCH PULL SERVICE] Retrieved ${entries.length} entries, ${validEntries.length} valid after sequence check`);
          
          // üîÑ COMMIT BATCH - ATOMIC TRANSACTION WITH QUOTA SAFETY
          try {
            await db.transaction('rw', db.entries, db.syncPoints, async () => {
              for (const entry of validEntries) {
                try {
                  // üõ°Ô∏è SAFETY GUARD: Validate completeness before storing
                  const validation = validateCompleteness(entry, 'entry');
                  if (!validation.isValid) {
                    errors.push(`Entry ${entry.cid} validation failed: ${validation.missingFields.join(', ')}`);
                    batchSuccess = false;
                    continue;
                  }
                  
                  const result = await this.commitSingleEntry(entry);
                  if (result.success) {
                    processed++;
                  } else {
                    errors.push(result.error || `Failed to commit entry ${entry.cid}`);
                    batchSuccess = false;
                  }
                } catch (error) {
                  errors.push(`Entry ${entry.cid} commit failed: ${error}`);
                  batchSuccess = false;
                }
              }
              
              // üéØ BATCH PROCESSING: Simplified without checkpoint saving
              if (validEntries.length > 0) {
                const maxSequence = Math.max(...validEntries.map((e: any) => e.sequenceNumber || 0));
                console.log(`‚úÖ [BATCH PULL SERVICE] Processed batch ${batchIndex} with ${validEntries.length} entries, max sequence: ${maxSequence}`);
                lastSequence = maxSequence;
              }
            });
          } catch (error: any) {
            // üíæ STORAGE QUOTA SAFETY: Handle quota exceeded gracefully
            if (error.name === 'QuotaExceededError' || error.message?.includes('quota')) {
              console.error('üíæ [PULL SERVICE] Storage quota exceeded, pausing sync gracefully');
              errors.push('Storage quota exceeded - please free up space');
              hasMore = false;
              break;
            } else {
              throw error; // Re-throw non-quota errors
            }
          }
          
          // üìä RECORD RESPONSE TIME AND CALCULATE DELAY
          const responseTime = Date.now() - batchStartTime;
          previousResponseTime = responseTime;
          previousFailed = !batchSuccess;
          
          // ‚è∞ ADAPTIVE THROTTLING
          const delay = this.batchProcessor.calculateOptimalDelay(responseTime, !batchSuccess);
          if (hasMore) {
            console.log(`üöÄ [BATCH PULL SERVICE] Waiting ${delay}ms before next batch (response: ${responseTime}ms, success: ${batchSuccess})...`);
            await new Promise(resolve => setTimeout(resolve, delay));
          }
          
          // üîÑ UPDATE OFFSET
          offset += entries.length;
          
          // üîç CHECK COMPLETION
          hasMore = entries.length === 20 && !batch.isComplete;
          
          this._progressTracker.updateBatch(batchIndex, validEntries.length);
          
        } catch (error) {
          console.error(`‚ùå [BATCH PULL SERVICE] Entry batch ${batchIndex} failed:`, error);
          errors.push(`Entry batch ${batchIndex} failed: ${error}`);
          batchSuccess = false;
          previousFailed = true;
          
          // Continue to next batch on failure
          offset += 20;
          hasMore = true;
        }
      }

      return { success: errors.length === 0, processed, errors };
    } catch (error) {
      console.error('‚ùå [BATCH PULL SERVICE] Entries pull failed:', error);
      errors.push(`Entries pull failed: ${error}`);
      return { success: false, processed, errors };
    }
  }

  /**
   * üìö COMMIT SINGLE BOOK
   */
  private async commitSingleBook(book: any): Promise<{ success: boolean; error?: string }> {
    try {
      // üõ°Ô∏è SCHEMA GUARD: Validate server data before storing
      const validationResult = validateBook(book);
      if (!validationResult.success) {
        const errorMsg = `üö® [PULL VALIDATOR] Server book data corruption blocked for ID: ${book.cid}. ${validationResult.error}`;
        console.error(errorMsg, { book });
        return { success: false, error: errorMsg };
      }

      // üîç CHECK-BEFORE-PUT: Check if local record exists
      const existing = await db.books.where('cid').equals(book.cid).first();
      
      // üõ°Ô∏è DIRTY BIT GUARD: Skip if local record has unsynced changes
      if (existing && existing.synced === 0) {
        console.warn(`üõ°Ô∏è [PULL SERVICE] Skipping book ${book.cid} - local changes pending push`);
        return { success: true }; // Skip but don't fail
      }
      
      // üõ°Ô∏è TIMESTAMP CONFLICT GUARD: Only overwrite if server is strictly newer
      if (existing && existing.synced === 1) {
        const localTime = new Date(existing.updatedAt || 0).getTime();
        const serverTime = new Date(book.updatedAt || 0).getTime();
        
        if (localTime >= serverTime) {
          console.warn(`üõ°Ô∏è [PULL SERVICE] Skipping Book ${book.cid} - local version is already up-to-date or newer`);
          return { success: true }; 
        }
      }
      
      // Normalize and store
      const normalized = normalizeRecord({
        ...book,
        userId: String(this.userId),
        synced: 1, // Server data is synced
        isDeleted: book.isDeleted || 0
      }, this.userId);
      
      // üìù [AUDIT] Log what we're storing in DB
      console.log('üìù [DB COMMIT]', { 
        cid: book.cid, 
        image: normalized.image, 
        mediaCid: normalized.mediaCid,
        hasLocalId: !!existing?.localId
      });
      
      // Preserve localId if it exists to ensure bulkPut updates correct record
      if (existing?.localId) {
        normalized.localId = existing.localId;
      }

      // üóëÔ∏è HARD DELETE CHECK
      if (book.isDeleted === 1 && existing) {
        await db.books.delete(existing.localId!);
        console.log(`üóëÔ∏è [PULL SERVICE] Book ${book.cid} hard deleted after pull`);
      } else if (book.isDeleted === 0) {
        // Store or update the book
        if (existing?.localId) {
          await db.books.update(existing.localId!, normalized);
          console.log(`‚úÖ [PULL SERVICE] Updated book: ${book.cid}`);
        } else {
          await db.books.add(normalized);
          console.log(`‚úÖ [PULL SERVICE] Added book: ${book.cid}`);
        }
      }
      
      return { success: true };
    } catch (error) {
      console.error('‚ùå [PULL SERVICE] Single book commit failed:', book.cid, error);
      return { success: false, error: `Exception for book ${book.cid}: ${error}` };
    }
  }

  /**
   * üìù COMMIT SINGLE ENTRY
   */
  private async commitSingleEntry(entry: any): Promise<{ success: boolean; error?: string }> {
    try {
      // üõ°Ô∏è SCHEMA GUARD: Validate server data before storing
      const validationResult = validateEntry(entry);
      if (!validationResult.success) {
        const errorMsg = `üö® [PULL VALIDATOR] Server entry data corruption blocked for ID: ${entry.cid}. ${validationResult.error}`;
        console.error(errorMsg, { entry });
        return { success: false, error: errorMsg };
      }

      // üîç CHECK-BEFORE-PUT: Check if local record exists
      const existing = await db.entries.where('cid').equals(entry.cid).first();
      
      // üõ°Ô∏è DIRTY BIT GUARD: Skip if local record has unsynced changes
      if (existing && existing.synced === 0) {
        console.warn(`üõ°Ô∏è [PULL SERVICE] Skipping entry ${entry.cid} - local changes pending push`);
        return { success: true }; // Skip but don't fail
      }
      
      // üõ°Ô∏è TIMESTAMP CONFLICT GUARD: Only overwrite if server is strictly newer
      if (existing && existing.synced === 1) {
        const localTime = new Date(existing.updatedAt || 0).getTime();
        const serverTime = new Date(entry.updatedAt || 0).getTime();
        
        if (localTime >= serverTime) {
          console.warn(`üõ°Ô∏è [PULL SERVICE] Skipping Entry ${entry.cid} - local version is already up-to-date or newer`);
          return { success: true };
        }
      }
      
      // Normalize and store
      const normalized = normalizeRecord({
        ...entry,
        userId: String(this.userId),
        synced: 1, // Server data is synced
        isDeleted: entry.isDeleted || 0
      }, this.userId);
      
      // Preserve localId if it exists to ensure bulkPut updates correct record
      if (existing?.localId) {
        normalized.localId = existing.localId;
      }

      // üóëÔ∏è HARD DELETE CHECK
      if (entry.isDeleted === 1 && existing) {
        await db.entries.delete(existing.localId!);
        console.log(`üóëÔ∏è [PULL SERVICE] Entry ${entry.cid} hard deleted after pull`);
      } else if (entry.isDeleted === 0) {
        // Store or update the entry
        if (existing?.localId) {
          await db.entries.update(existing.localId!, normalized);
          console.log(`‚úÖ [PULL SERVICE] Updated entry: ${entry.cid}`);
        } else {
          await db.entries.add(normalized);
          console.log(`‚úÖ [PULL SERVICE] Added entry: ${entry.cid}`);
        }
      }
      
      return { success: true };
    } catch (error) {
      console.error('‚ùå [PULL SERVICE] Single entry commit failed:', entry.cid, error);
      return { success: false, error: `Exception for entry ${entry.cid}: ${error}` };
    }
  }

  /**
   * üîÑ SET USER ID
   */
  setUserId(userId: string): void {
    this.userId = String(userId);
  }

  /**
   * üåê BACKGROUND MEDIA DOWNLOADER - Hydrate missing media blobs for offline persistence
   */
  private async hydrateMissingMedia(imageUrl: string, bookId: string): Promise<void> {
    // üöÄ [AUDIT] Aggressive logging at function entry
    console.log('üöÄ [DOWNLOADER TRY]', { url: imageUrl, book: bookId });
    
    try {
      // üõ°Ô∏è SKIP GUARDS: Only process HTTP URLs (Cloudinary)
      if (!imageUrl || !imageUrl.startsWith('http')) {
        console.warn('üö´ [DOWNLOADER] Skipped - not HTTP URL:', imageUrl);
        return;
      }

      // üõ°Ô∏è DUPLICATE CHECK: Skip if media already exists locally
      const existingMedia = await db.mediaStore.where('parentId').equals(bookId).first();
      if (existingMedia) {
        console.log(`üåê [MEDIA DOWNLOADER] Media already exists for book ${bookId}, skipping download`);
        return;
      }

      // üåê FETCH BLOB: Download image from Cloudinary
      console.log(`üåê [MEDIA DOWNLOADER] Downloading media for book ${bookId} from ${imageUrl}`);
      const response = await fetch(imageUrl);
      if (!response.ok) {
        throw new Error(`Failed to fetch image: ${response.status}`);
      }

      const blob = await response.blob();
      if (!blob || blob.size === 0) {
        throw new Error('Empty blob received from server');
      }

      // üß™ GENERATE CID: Create unique identifier for media
      const { generateCID } = await import('@/lib/shared/utils');
      const mediaCid = generateCID();

      // üíæ STORE IN MEDIASTORE: Save blob with metadata
      await db.mediaStore.add({
        cid: mediaCid,
        parentType: 'book',
        parentId: bookId,
        localStatus: 'uploaded', // Mark as uploaded since we got it from server
        blobData: blob,
        mimeType: blob.type,
        originalSize: blob.size,
        compressedSize: blob.size,
        createdAt: Date.now(),
        userId: this.userId
      });

      // üîÑ UPDATE BOOK: Link book to media CID
      await db.books.where('localId').equals(bookId).modify({
        image: imageUrl, // Keep original URL
        mediaCid: mediaCid, // Add local CID reference
        updatedAt: Date.now()
      });

      console.log(`‚úÖ [MEDIA DOWNLOADER] Successfully downloaded and stored media for book ${bookId} (CID: ${mediaCid})`);

    } catch (error) {
      // üõ°Ô∏è SILENT FAILURE: Don't block main sync process
      console.warn(`‚ö†Ô∏è [MEDIA DOWNLOADER] Failed to download media for book ${bookId}:`, error);
      // Continue without failing the entire pull operation
    }
  }

  /**
   * üîÑ PULL FULL DATASET - For hydration consolidation
   */
  public async pullFullDataset(type: 'BOOKS' | 'ENTRIES'): Promise<{ success: boolean; data?: any[]; error?: string }> {
    try {
      console.log(`üîÑ [PULL SERVICE] Full dataset pull for ${type}`);
      
      const endpoint = type === 'BOOKS' ? '/api/books' : '/api/entries';
      const response = await fetch(`${endpoint}?userId=${encodeURIComponent(this.userId)}&limit=10000`, { method: 'GET' });
      
      if (!response.ok) {
        throw new Error(`Failed to fetch ${type}: ${response.statusText}`);
      }
      
      const result = await response.json();
      const data = result.data || result[`${type.toLowerCase()}`] || [];
      
      console.log(`‚úÖ [PULL SERVICE] Retrieved ${data.length} ${type}`);
      return { success: true, data };
      
    } catch (error) {
      console.error(`‚ùå [PULL SERVICE] Full dataset pull failed for ${type}:`, error);
      return { success: false, error: String(error) };
    }
  }

  /**
   * üéØ PULL SINGLE ITEM - For sniper hydration
   */
  public async pullSingleItem(type: 'BOOK' | 'ENTRY', id: string): Promise<{ success: boolean; data?: any; error?: string }> {
    try {
      console.log(`üéØ [PULL SERVICE] Single item pull for ${type} ${id}`);
      
      const response = await fetch(`/api/${type.toLowerCase()}s/${id}`, { method: 'GET' });
      
      if (!response.ok) {
        if (response.status === 404) {
          return { success: true, data: null }; // Item gone
        }
        throw new Error(`Failed to fetch ${type}: ${response.statusText}`);
      }
      
      const result = await response.json();
      const data = result.data || result;
      
      if (!data) {
        console.warn(`‚ö†Ô∏è [PULL SERVICE] ${type} not found for ID: ${id}`);
        return { 
          success: false, 
          error: `${type} not found for ID: ${id}`
        };
      }
      
      console.log(`‚úÖ [PULL SERVICE] Retrieved ${type} ${id}`);
      return { success: true, data };
      
    } catch (error) {
      console.error(`‚ùå [PULL SERVICE] Single item pull failed for ${type} ${id}:`, error);
      return { success: false, error: String(error) };
    }
  }


  /**
   * üîÑ GET PULL STATUS
   */
  getPullStatus(): { isPulling: boolean; userId: string } {
    return {
      isPulling: this.isPulling,
      userId: this.userId
    };
  }
}
